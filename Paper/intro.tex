%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\indent
The United States Patent Office (USPTO) granted 276,788 patents in 2012\cite{USPTO:2013:stats}. This is more than double the number granted 20 years ago, and rate of filings is still increasing. In the circumstance it makes sense to consider scalable, automated approaches to parts of the patent review process. To this end we examined attempting to classify patents into existing categorizations using supervised machine learning techniques. We also attempted to measure the coherency and usefulness of the classifications. Reliable automation of patent categorization is an important first step to larger scale automation of the patent review process.

In this paper we experimented with several machine learning classifiers to automatically categorize patents into each of the 8 top-level patent categories specified in the International Patent Classification\cite{ipc:2013:guide} (IPC). The USPTO is moving from its previous classification system (which contained thousands of classes and was deemed unsuitable for standard machine learning classification techniques) to the Cooperative Patent Classification (CPC), which is a superset of the IPC. The USPTO labels with an IPC Classification in preparation for this conversion. The CPC classification conforms to the IPC classification, but also contains one additional category, Y, which is for patents on technologies that span several sections of of the IPC classification. All patents must contain at least one primary classification, but may be assigned more if they are relevant to multiple IPC classes. In our experiments we only attempted to classify the primary classification.


% Relative size of categories?

\begin{tablehere}
	\centering
	\caption{IPC Classifications and their titles}
	\begin{tabular}{ | l | l |}
		\hline
		\textbf{Class} & \textbf{Title} \\
				\hline
		A & Human Necessities \\
				\hline
		B & Performing Operations; Transporting \\
				\hline
		C & Chemistry; Metallurgy \\
				\hline
		D & Textiles; Paper \\
				\hline
		E & Fixed Constructions \\
				\hline
		F & Mechanical Engineering; Lighting; Heating; Weapons; Blasting Engines or Pumps \\
		\hline
		G & Physics \\
				\hline
		H & Electricity \\
				\hline
	\end{tabular}
	
\end{tablehere}



%Many of these patents are awarded to so-called nonpracticing entities (NPEs), organizations that do not design, build (or even prototype) the techniques and technologies under patent, but rather create or invest in patent portfolios to litigate against organizations or individuals that build related products. At the same time, patent litigation has been increasing, particularly litigation initiated by NPEs\cite[p. 7]{PWC:2013:lit}. In such an environment, it is more important than ever to be able to quickly and reliably assess the quality of patents, both in terms of their content, and whether they represent truly original work. 

% More Here!!

%The structure of the brain influences availability and access to the memories stored therein. Communication between neurons allows animals to think, move, and store or recall memories. It seems plausible that the structure of an artificial neural network would similarly affect the ability of that neural network to store and process information. Building off this idea, we suggest a new model of neural network influenced by Perin, Berger, and Markram (2011) who proposed that the brain is composed of a hierarchy of connected components with specific associated computational functions. 

%We implemented this model within the framework of deep learning inspired by Hinton (2007).  More specifically, we describe a model of deep learning based on the use of acyclic clusters which mimic multiple layers of neurons. Additionally, these clusters themselves are layered. We found that this model did not significantly increase the ability of our network to generate or classify handwritten digits, nor did it increase the computational efficiency of those tasks.
%\label{sec:Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Some text, cite this~\cite{ASBMI,Acharya07}, and also Figure~\ref{fig:something}.