\section{Classification Evaluation} % (fold)
\label{sec:classification_evaluation}

The IPC classification system was initially created in 1968. Although the subcategories have been changed an expanded since that time, the 8 main top-level categories have not been altered. In the 45 years since the categories were initially established the technological landscape has changed greatly and they may not be as relevant to current and future patent applications. We used several unsupervised techniques and metrics to attempt to evaluate the suitability of the 8 top-level IPC categories.

\ref{tab:skew}Table XXXX shows the proportion of each label class found in \emph{jagged-40000}. We can see that the distribution of patents between the categories is highly skewed, with <ADD CONTENT>. As a first approximation it is desirable that each category occur with roughly equal frequency. Extreme imbalances in the proportions of categories in a sample implies that some are too specific and others are too general. This initial intuition is borne out by metrics of topic coherence that have been used to evaluate the quality of topics generated by unsupervised techniques. We used a coherence metric that compares document frequency with co-document frequency\cite{Mimno_optimizingsemantic}. Specifically, if we define $D(v)$ to be the number of documents in a corpus that contain a given word $v$, $D(v, v')$ to be the number of documents in a corpus that contain both $v$ and $v'$, and $V^{(t)}_M$ to be the $M$ most common words in topic $t$, then we define the coherence of a topic $t$ to be:
\begin{align*}
	C(t;V^{(t)}) = \sum_{m=2}^M \sum_{l=1}^{m-1} \log \frac{D(v^{(t)}_m, v^{(t)}_l)}{D(v^{(t)}_l)}
\end{align*}

This metric is essentially an unnormalized pointwise mutual information, but has been shown to perform better as a coherency metric\cite{Mimno_optimizingsemantic}. In practice we found that pure frequency counts did not produce useful coherency scores since despite our general and domain specific stopwords many of the most common words appeared in all categories. To alleviate this problem we calculated tf-idf weights (essentially regularizing the term frequencies by the document frequencies). Using this modified metric we calculated coherence scores for each of the IPC classifications in \emph{jagged-40000}. We calculated these scores based on the 50 most common words in each. These coherency scores confirm the initial intuition from examining the proportions - that the IPC classifications are heavily imbalanced partitions of the set of modern patents, with some categories referring to very narrow topics and others covering a very broad range.

%\begin{table}
	\begin{table}
		\centering
		\caption{proportions for IPC classes in \emph{jagged-40000}}
		\begin{tabular}{| l | c |}
			\hline
			\textbf{Class} & \textbf{Proportion} \\ 
					\hline
			A &  \\
					\hline
			B &  \\
					\hline
			C &  \\
					\hline
			D &  \\
					\hline
			E &  \\
					\hline
			F &  \\
			\hline
			G &  \\
					\hline
			H &  \\
					\hline
		\end{tabular}
	\end{table}
%	\quad
	\begin{table}
		\centering
		\caption{coherence scores for IPC classes in \emph{jagged-40000}}		
		\begin{tabular}{| l | c |}
			\hline
			\textbf{Class} & \textbf{Coherence} \\ 
					\hline
			A &  \\
					\hline
			B &  \\
					\hline
			C &  \\
					\hline
			D &  \\
					\hline
			E &  \\
					\hline
			F &  \\
			\hline
			G &  \\
					\hline
			H &  \\
					\hline
		\end{tabular}
	\end{table}
%\end{table}

%Table of topics


%Coherence

%In addition to determining how to best classify patents using the CPC labeling scheme, we wanted to evaluate the class system defined by the Patent office.  The patent class system takes it's class structure from the International Patent Classification scheme originated as a result of 1956's European Convention on the International Classification of Patents for Invention in 1968.  Since it's origin, it has been updated in eight editions, the last in 2006.  Despite multiple editions, the top eight categories we examine in this work have not been altered.
  
%While the top structure has remained the same, the different types of new technologies are ever changing.  
%As many Machine Learning problems have shown previously, tasks which are easy for human's are not easy for machines.  The distinction between a patent in the field of physics and a patent in the field of electricity becomes a difficult problem when the classifier has to rely on only n-grams of terms. 

%We observed in our samples that the distribution of incoming patents is shewed.  The proportions of each group in our dataset of patents can be seen in Table Z.  It can be assumed that this distribution can be generalized to the full set of patents.  To investigate how this affects supervised classification, we employed unsupervised methods to generate topics from the dataset of patents.  

 
%\subsection{Topic Coherence}
\begin{tablehere}
\begin{center}
\caption{Maximum Entropy with Dimensionally Reduction}
\begin{tabular}{| p{0.7\textwidth} |}
\hline

\multicolumn{1}{|c|}{\textbf{Topic Terms}} \\ \hline
large updating, establish database, accessible receive, users store, store health\\ \hline

checks brake, predetermined brake, pressure addition, addition checks, checks speed\\ \hline	

prismatic face, face InGaN, InGaN base, semiconductor heterostructure, heterostructure median\\ \hline

blend multiple, fibers dimensionally, dimensionally spirally, spirally crimped, crimped selected\\ \hline

measured flue, period formed, combustion reduced, addition decrease, Disclosed pool\\ \hline 

displacement cursor, cursor cost, CI consecutive, consecutive dependent, dependent discrepancy\\ \hline 

automated measurements, measurements iterative, iterative calculations, calculations controls, routine device\\ \hline

signing media, media streams, streams processed, processed accommodate, accommodate resource\\ \hline
\end{tabular}
\end{center}
\end{tablehere}

%Investigate where things should be split

% section classification_evaluation (end)